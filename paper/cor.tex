% MEng project
% CH1 --- background
%
\documentclass[12pt, a4paper, pdflatex, leqno, twoside, openright]{report}

% Define margins
\usepackage[a4paper,inner=40mm,outer=20mm,top=20mm,bottom=25mm,pdftex]{geometry}

\usepackage[T1]{fontenc} % polsih

% Harvard citation
\usepackage[square]{natbib}
\usepackage{cite} % BiTeX

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{url}
\usepackage{listings}

\usepackage{datetime}
\newdateformat{monthyeardate}{%
  \monthname[\THEMONTH] \THEYEAR}

% New commands
\newcommand{\ts}{\textsuperscript}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\newenvironment{dedication}
  {\clearpage               % we want a new page
   \thispagestyle{empty}    % no header and footer
   \vspace*{\stretch{1}}    % some space at the top 
   \itshape                 % the text is in italics
   % \raggedleft            % flush to the right margin
   \raggedright             % flush to the right margin
   \par\setlength{\leftskip}{0.3\textwidth}\noindent\ignorespaces
  }
  {\par                     % end the paragraph
   \vspace{\stretch{3}}     % space at bottom is three times that at the top
   \clearpage               % finish off the page
  }

\usepackage{lipsum}
\begin{document}

\begin{titlepage}
  \begin{center}
\includegraphics[width=0.5\textwidth]{gfx/UOB-logo.png}~\\[2.5cm]

\HRule \\[0.4cm]
{\huge \bfseries
  {\Huge Building activity recognition model:}\\[0.1cm]
  learning Prolog rules and extracting features from spatio-temporal data\\[0.4cm]
}
\HRule \\[1.5cm]

    \begin{minipage}{0.4\textwidth}
      \begin{flushleft} \large
\emph{Author:}\\
Kacper B. \textsc{\textbf{Sokol}}
      \end{flushleft}
    \end{minipage}
    \begin{minipage}{0.4\textwidth}
      \begin{flushright} \large
\emph{Supervisor:} \\
Prof.\ Peter \textsc{\textbf{Flach}}
      \end{flushright}
    \end{minipage}

\let\thefootnote\relax\footnote{\hspace*{-1.7em}Level M/7 $|$ COMSM0130---40cp Individual Project}

\vfill % Bottom of the page
{\large \today}
  \end{center}
\end{titlepage}

\newpage
\thispagestyle{empty}
\mbox{}

\newpage
\thispagestyle{empty}
\mbox{}

% Acknowledgement
\begin{center}\textbf{Declaration}\\[1em]\end{center}
This dissertation is submitted to the University of Bristol in accordance with the requirements of the degree of Master of Engineering in the Faculty of Engineering. It has not been submitted for any other degree or diploma of any examining body. Except where specifically acknowledged, it is all the work of the Author.\\[1.5cm]
Kacper B.\ Sokol, \monthyeardate\today

\newpage
\thispagestyle{empty}
\mbox{}

% Abstract
\begin{abstract}
\thispagestyle{empty}
This project describes \texttt{Prolog}'s \emph{Inductive Logic Programming} approach to learn parametrised rules describing \emph{human activities}. To this end, \emph{Activity Recognition Model} is constructed based on data collected from installations such as smart houses and smart cities. Such sites characterise with vast number of sensors monitoring place of interest, therefore, allow for detailed tracking of \emph{atomic actions} that contribute towards more general activities.\\
Constructed model can be then used to analyse output from smart sites, therefore, describe ongoing human activities. Then, the model is extended to facilitate monitoring of multiple people simultaneously e.g.\ multiple occupiers of a flat.\\
Another, application is to discover structure in the data. Identifying dependencies between sensors and constructing new, more informative features is shown. Both approaches aim at improving performance of classification and are compared and contrasted against the currently most popular model in use: conditional random fields.\\
Furthermore, proposed Activity Recognition Model is extended with basic \emph{Narrative Analytics}. Its goal is to transform generated rules to \emph{natural language}, therefore, produce human readable description of monitored activities.\\

To achieve aforementioned goals, signal issues such as noise, errors, and incompleteness among others are addressed. Furthermore, data transformation is presented: expressing sensors output as knowledge facts. Proposed tool helps to present acquired data in a more transparent way mainly for healthcare applications.\\

To build and test proposed framework both SPHERE Project, and Washington State University CASAS datasets are used.



\begin{center}
Keywords: \textbf{Inductive, Logic, Programming, Prolog, Activity, Recognition, Model, SPHERE}

\let\thefootnote\relax\footnote{\noindent This publication including source code is available as \texttt{GIT} repository at: \url{https://github.com/So-Cool/cognition}.}
\end{center}
\end{abstract}



\newpage
\thispagestyle{empty}
\mbox{}
\begin{dedication}
``\ldots~On each landing, opposite the lift-shaft, the poster with the enormous face gazed from the wall. It was one of those pictures, which are so contrived that the eyes follow you about when you move. BIG BROTHER IS WATCHING YOU, the caption beneath it ran.~\ldots''\\[1cm]

``\ldots~The telescreen received and transmitted simultaneously. Any sound that Winston made, above the level of a very low whisper, would be picked up by it, moreover, so long as he remained within the field of vision which the metal plaque commanded, he could be seen as well as heard. There was of course no way of knowing whether you were being watched at any given moment. How often, or on what system, the Thought Police plugged in on any individual wire was guesswork. It was even conceivable that they watched everybody all the time. But at any rate they could plug in your wire whenever they wanted to. You had to live did live, from habit that became instinct in the assumption that every sound you made was overheard, and, except in darkness, every movement scrutinized.~\ldots''\\[2cm]

Nineteen Eighty-Four, George Orwell
\end{dedication}


\newpage
\thispagestyle{empty}
\mbox{}

\newpage
\cleardoublepage
\pagenumbering{gobble}
\tableofcontents
\cleardoublepage
\pagenumbering{arabic}

% \newpage
% \thispagestyle{empty}
% \mbox{}

%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
\chapter{Introduction\label{ch:introduction}} %Background
\setcounter{page}{1}
% -------- plain English -> explain to someone
% Start with motivation - what is the problem and why it's interesting
% SPHERE somewhere here
% and application - what to do with it
% give solution
% then technique - why technique is best for solution - and more technical details
% --------
% What the project will produce -> contribution
% level of technical challenge
% how the output will be assessed - evaluation
% --------

  \section{The activity recognition}
    \subsection{Outline} %Problem outline
The main aim of the project is to build \emph{activity recognition model} for \emph{smart house} monitoring purposes.\\
By the latter I understand a premise that is fitted with variety of sensors like: motion, door, appliances, water, item, etc.; as well as more sophisticated monitoring devices like cameras, and depth cameras. The first kind of sensors generate raw output usually of a form \texttt{sensorID on}/\texttt{sensorID off}, while the latter type outputs complex signal that needs to be pre-processed to be used as an input of classifiers. Due to aforementioned sensor characteristics my work is mainly focus on the first type of sensors.\\
Therefore in presented above scenario, activity recognition model is a set of techniques that applied to real time signals generated by a house produce a prediction of currently held activity like \emph{cooking} or \emph{sleeping} assigned to one of the premise \emph{residents}. The best solution to sketched above problem is one that works in \emph{signal streaming environment} therefore producing real-time activity predictions with high recognition rate.

    \subsection{Motivation} %Problem motivation/Applications
% Why interesting -> it generalises to any spatio-temporal data therefore can be used
Proposed here activity recognition model is a special case of \emph{predictive model} for \emph{spatio-temporal} data. In general such techniques predict quantity of interest based on input data that encode both location and time of the event of interest.\\
% Why is it needed -> spatio-temporal data is everywhere,
This generalisation have wide variety of real-life applications therefore addressing problems defined as ``hard'' in the activity recognition literature would make valuable contribution to the field. 
First and foremost area of application is healthcare.
% Population ageing - society geting older,  SPHERE project

      \subsubsection{Healthcare: The SPHERE Project}
Allowing elderly people and clinical patients to live at home regardless of health conditions they suffer greatly benefits such individuals. Dwelling in cosy environment causes less stress and individuals being located at home means no need for specialistic day care centres and less crowded hospitals.\\
Therefore, being able to monitor behaviour of people in their own houses and effectively describe their activities result in better patient care possibilities. Such methods allow quick response to any kind of incidents without disturbing monitored people when it is unnecessary.

\begin{figure}
  \centering
  \includegraphics[scale=.5]{./gfx/populationOver65}
  \caption{Percentage of world population over 65, 1950--2050; \citep{populationAgeing}.\label{fig:agingPopulatiom}}
\end{figure}

% The Challenge
The problems of ageing population (see \emph{Figure~\ref{fig:agingPopulatiom}}), global population health issues, increasing healthcare costs, and decreasing quality of life are addressed by the \emph{SPHERE Project} hosted at the University of Bristol \citep{sphere}. This collaboration of clinicians, engineers, designers, social care professionals and various members of the public develops helpful technologies addressing real healthcare problems in a cost effective way.\\
The project focuses on developing real-world technologies which are acceptable in people's homes i.e.\ do not hindering everyday-life. SPHERE works on both hardware and software smart house solutions: sensors and wearable devices as well as algorithms for healthcare applications. The first, are fitted in the place of interest to monitor it and generate various kind of signals, while the latter, use acquired information to identify medical or well-being issues: predict falls, detect strokes, analyse eating behaviour, and detect periods of depression or anxiety.\\
This project extends algorithmic part of undertaken by SPHERE research by proposing novel data analysis framework.

      \subsubsection{Smart City}
Despite huge popularity in healthcare, spatio-temporal data feeds can also be found in variety of monitoring applications. One of them described by \citet{filipponi2010smart} is smart-city management. Automatic analysis---quick and robust---of traffic information, accident reports, etc.\ is of invaluable help in case of emergency.\\
Among many possible applications, produced analysis can result in timely police intervention or well planned route for emergency services, therefore, help in evacuation, crowd management, terrorist attack prevention and airport security control.

      \subsubsection{Complex Systems}
Spatio-temporal data is also produced in large quantities by many of complex systems monitoring and control devices, e.g.: scientific facilities, buildings, data centres~\citep{moore2005data} and power plants~\citep{amin2005toward}. 
Tasks impossible to handle by humans either due to large data volume throughput or demand for low response time are vast area of application for spatio-temporal data analysis. Such tools facilitate well suited for needs system management and risk detection. Power distribution and balancing, nuclear reactor control, data centre heat management are such tasks to name a few.

      \subsubsection{Wildlife}
Monitoring animals behaviour in their natural habitat is an important source of information for many researchers~\citep{Szewczyk:2004:HMS:990680.990704}. Nevertheless, this task is very often impractical either due to adverse climate or difficult access to monitored place. Moreover, scientists in many cases want to avoid disturbing animals' life-cycle and habitats. Difficult access to such sites can be easily overcome with wide range of available sensors and analytic tools, which share common ground with activity recognition model.


  \section{Contribution}
    \subsection{Existing work}
Over the last few years, building machine learning models for \emph{Activity of Daily Living} (ADL) has become an interest of many researchers. Its wide area of applications and increasing complexity appearing with every new discovery attracts now and then machine learning community with new and innovating ideas.\\

    \subsubsection{Techniques}
Up to date, extensive work on houses occupied with both \emph{single}~\citep{cook2009assessing,fatima2013unified} and \emph{multiple}~\citep{hsu2010strategies,singla2010recognizing,crandall2009coping} residents has been done, nevertheless, vast majority focused on state-of-the-art learning algorithm such as:
\begin{itemize}
\item transfer learning---\citet{cook2013transfer},
\item conditional random field---\citet{hsu2010strategies,van2010activity},
\item support vector machines with various kernels---\citet{fatima2013unified},
\item hidden Markov model---\citet{rashidi2011discovering},
\item na\"{\i}ve Bayes---\citet{cook2013activity},
\item artificial neural networks---\citet{fatima2013unified,fatima2013analysis}.
\end{itemize}

All of these models are fuelled by variety of features extracted from raw signals by transformation and time manipulation. Majority of undertaken work in this field uses motion sensors as main source for feature construction with little to none attention to item sensors.\\

Unfortunately, scientific environment focuses on mainstream models and forget about possibly simpler and more suitable but less popular techniques. Observing this gap in spatio-temporal data analysis opens vast new area of research of building activity recognition models with less popular machine learning techniques which is addressed in this paper.

      \subsubsection{Datasets}
Training and testing any activity recognition model requires a dataset of recorded human activities. Such data can be only obtained by designing and building a test-bed house fitted with variety of sensors followed by numerous ``plays'' of scripted activities. As majority of researchers cannot invest time or money to construct a smart house they use publicly available datasets generated by one of research facilities. The most popular choice~\citep{fatima2013unified,fatima2013analysis,nazerfard2010conditional,cook2009assessing} among researchers are datasets published by \citet{cook2009assessing} working at \emph{Center for Advanced Studies in Adaptive Systems}, Washington State University; also known as \emph{CASAS datasets}.\\
Their popularity is based on large amount of variety of recorded activities, with both single and multiple occupiers, available publicly free of charge. Furthermore, they are fairly well formatted and documented nevertheless, they sometimes show inconsistency with labelling structure.

      \subsubsection{Issues}
Tasks such as activity recognition aim at predicting nearly infinite amount of human activities which can be performed in variety of manners. This enormous complexity of the task causes numerous problems ranging from activity prediction, to assigning one of multiple occupiers to performed task. Such ``multi layered'' predictions yield many possibilities for assessing performance e.g.\ correct activity, wrong agent prediction; correct activity, correct agent prediction; etc..\\

The literature identifies building model for some of the activities as relatively difficult. Many of them involve complex, time consuming tasks with multiple residents crossing each others paths. Some of them are addressed in latter parts of this work.\\

Finally, due to specific to dataset output formatting and sensor name-space learnt models are not universal.

      \subsubsection{Outcomes}
Outcomes of activity modelling tasks reported in the literature are unfortunately poor reference for assessing model performance. Use of different datasets and fitness measures depending on study make result comparison impractical.\\
For instance,~\citet{fatima2013analysis} report \emph{accuracy} ranging from $\sim0.2$ to $\sim1.0$ depending on model, dataset and predicted activity.


    \subsection{Project contribution}
Broad activity recognition literature and variety of tested therein models clearly indicate that no single classifier can handle diversity of activity structures embedded in the data. Each model has its pros and cons therefore perfect solution should use all of the models offering features not covered by the others---the concept known as \emph{ensemble learning}.\\

As none of published so far piece of literature discusses application of \emph{first-order formulas} i.e.\ parametrised logical rules, as building blocks of activity recognition model this work comprehensibly covers this problem to expand collection of used techniques. Therefore, the main aim of the project is to apply \emph{Inductive Logic Programming} (ILP) techniques to spatio-temporal data acquired from ``smart'' installations---houses in particular---in order to build \emph{Activity Recognition Model} and extract new, more informative features from raw signals.\\

To address the first problem capabilities of ILP system and model description via set of first-order logical rules are investigated. Both cases: houses with single and multiple occupiers are examined.\\
The latter task involves critical analysis of designed for model learning signal features and assessing their quality. Such novel signal characteristics can be used in any other activity recognition model to boost its performance.\\

Designing a new model and signal features can become difficult task when exact structure of used dataset is unknown. Therefore, systematic way of \emph{generating smart-house data} within user controlled environment is desirable. As part of this project highly customisable data generator is proposed. Such tool facilitates generating datasets representing activities of arbitrary complexity therefore produced data can be used to build and test activity recognition models in (in)deterministic world simulation. Moreover, produced by the generator datasets are invaluable help to systematically compare and contrasting all the learning methods.\\

Finally, the project aims at proposing \emph{unified activity-recognition model evaluation measures}. A systematic way of assessing performance of classifier in activity recognition tasks is beneficial for comparing and contrasting multiple solutions. With such techniques unambiguous assessment of multiple methods for particular activity is possible yielding obvious identification of best solution.

\section{Techniques}
To achieve set above goals performance of proposed technique is evaluate on both \emph{CASAS datasets} and \emph{CASAS-inspired synthetic} datasets produced by the generator. Both datasets are translated from log-like format into \emph{knowledge representation} i.e.\ sensor readings are expressed as logical facts. The evaluation is made by means of \emph{cross-validation}. CASAS datasets are split into activities per person to produce folds so that each fold contains number of activities performed by single person. On the other hand, when evaluating synthetic data each fold is generated independently with common activity structure and small variation of order of used items and detours from originally planned motion trajectory.\\

% why I think it's best for the problem -> more details
The core of proposed technique is \texttt{ALEPH}---Inductive Logic Programming system producing \texttt{Prolog} clauses as the model of data. This approach to learning activity recognition model was chosen as it lacks needed attention in the subject literature.\\

Proposed here rule based classifier greatly differs from currently used methods. Instead of employing \emph{propositional logic} it uses more powerful first-order logic, to express data and activity structure believes. More advanced ``grammar'' implies more possibilities to express complex relations between sensor events. This extra power can be harnessed to compose new data features which can be used in training other models and potentially improve their performance.\\

Furthermore, expressing the activity model in \texttt{Prolog} programming language brings to power all its advantages. Easy \emph{search space traversal} and built-in \emph{failure by negation} are invaluable tools in feature construction. Finally, learnt activity recognition model can be easily transformed to a \emph{generative model} for data hence, serve as an activity example generator.\\
\texttt{Prolog} is also well known for its \emph{natural language processing} capabilities. Rule based model can be therefore used to produce \emph{Data Narrative}---a plain English interpretation of the data which supersedes any other visualisation technique targeted at general public.\\

Another advantage of ILP learning is use of \emph{background knowledge}. It encodes \emph{clauses} needed to build the target model but can also contain any information or rules that might be beneficial for raw data interaction.\\
In smart-house model such component is of invaluable help as it can contain all the house and activity details that are absent in raw data. Room layout, sensor placement, activity structure are just some of them.\\
Moreover, background knowledge acts as a \emph{proxy} between raw data and model, making the latter universal. It means that in majority of cases model learnt for one dataset can be applied to any other by using data-specific background knowledge.\\

Very often monitored activities exhibit hierarchy and structure. Rule based model allow to easily adjust the \emph{resolution of prediction} therefore, activities can be described with different level of depth. Considering activity of eating, the model can simply predict the activity: \emph{eating}; it can also suggest meal type (breakfast, lunch, brunch, etc.) based on time of day; or even food type (pasta, pizza, etc.) based on used ingredients.\\

Rule based model has one more distinctive feature not exhibited by many other machine learning models: it is \emph{human readable}. Such models are easy to inspect and tune simply by eye-balling. Rules can be evaluated whether they make sense, obscure information can be discover and gained knowledge used to design new more suitable features in iterative manner. Rule manipulation is also feasible therefore, they can be simplified (by removing predicate), extended (by appending predicate), or combined (by enclosing them in meta-rule).\\

\section{Deliverables}
% Deliverables / contribution -> what the project will result in
The project delivers highly customizable smart-house data generator written in \texttt{Python}. It is publicly available as a \texttt{GitHub} repository\footnote{\noindent\url{https://github.com/So-Cool/SHgen}} to help researchers with training and testing models.\\
The smart-house simulator is highly customisable: room layout, motion and item sensor placement, and number of occupiers can be specified. The user specifies \emph{action script} which is then ``played'' by house occupiers what in turn produces sensor activations which are recorded in CASAS-like format.\\
As all the actions are ``directed'' precise \emph{ground truth} information is available. Presence of \emph{activity labels} in the data and precise control over the sensor interactions is of invaluable help in experiments of this kind. Finally, the data generator is proved to produces real-like data therefore it is sound for use in model creation and evaluation.\\
The generator repository contains detailed design and usage description to be easy to set-up and use for anybody. The choice of programming language was made based on its popularity making contribution, maintenance and development easy for whole community.\\

Moreover, the project studies in great detail application of ILP to various smart-house settings. Signal output as knowledge representation is proposed. Activity recognition problems defined in literature as ``hard'' for both single and multiple residents are attempted and quality of results is discussed. The capabilities, limitations and advantages of ILP in described scenario is thoroughly investigated and illustrated with examples. The role of background knowledge encoding additional signal characteristics is examined. Used signal features are described and their role in model construction is critically evaluated. Finally, result evaluation techniques are proposed and used to score achieved results.

\section{Challenges}
Lack of labelled data to train and test models Incompleteness of data
Noisy data
Time handling (unbounded variable)
Real valued sensor output
Information loss: room and sensor layout

􏰁Design customisable spatio-temporal (smart house) data generator to test and design models
􏰀􏰁Investigate spatio-temporal data representation as logical facts
􏰀􏰁Research representation of unbounded variables like time in first-order logic
􏰀􏰁Examine use of background knowledge not contained in the original dataset
􏰀􏰁Create and test different activity recognition models in ILP 􏰀􏰁 Build mechanism for new features discovery


Lack of labelled data to train and test models -> not knowing what is in real data -> therefore neeed to emulate some to check it out
time represenataition - unbounded variable in aI and ILP: time and real-valued sensors
data noise and incompleteness
Information loss: room and sensor layout
incompleteness and noise in the data
tuning ILP systemin this case ALEPH, to build activity recognition model
design of features to extract relevant information form data
design of background knowledge to extract the features
prediction continuity issues, and readings in time continuity issues
adjusting resolution of the rules -> detail of prediction -> meal -> what kind of meal -> etc. -> level of depth -> dicover hierarchy -> chain of sub-activities contributing to the main action, or state which sensor or sequence of sensors build such actions.
what evaluation techniques to use -> multiple error possibilities
multiple residents dicovery -> Most often monitored places are inhabited or being used by multiple people. Another important task that can be performed with proposed technique is identifying actions and agents associated with them when multiple users simultaneously share observed space.

Very often the data collected from smart houses is corrupted or obscure due to sensor noise, leading to confusing gaps between ``observed'' actions. With help of inductive learning such implicit information---describing intermediate steps between actions---can be inferred to overcome rule creation difficulty and produce logically consistent scenario. This in turn can be translated into natural language using second ``grammar''.\\

Finally, data derived from smart houses is highly structured. Human activities can be hierarchically organised with complex actions composed of sub-actions, until ``atomic level'' is reached. This creates possibility to apply filters to produce multiple levels of narrative complexity based on target audience. Adjusting level of detail (granularity) of produced description would result in emphasis on different aspects of carried out activities during period of interest, hence, extracting relevant for the audience information.

\section{Result evaluation}
Proof of generator

OUtput asses ->
assess the generator by applying models learnt on real data and on generated data to prove bidirectionality
use cross validation with random bits in generated data
use models learnd on data and vice versa to assess it
used CRF on both generated data and real data to compare results
genuine data can be split per person (each person doing 5 diff activities) -> cross validated
single occupier data can be coverteed to ARFF format and different models in Weka can be used to check it out



%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
\chapter{Spatio-temporal data\label{ch:stData}}

  \section{The data}
Introduce the data
--What the data looks like

The spatio-temporal class of data is of interest. Data-points in such sets are characterised by both location and time of the event. Such data are generated by all smart instillations like houses and cities. In this study smart house data are used but the generalisation of the solution is straight forward.\\ % specification

The datasets used for model building and testing are ones generated at \emph{Washington State University} as part of \emph{CASAS} project~\citep{cook2009assessing}. \emph{WSU Smart Apartment ADL Normal Testbed} and \emph{WSU Smart Apartment ADL Error Testbed} are the two most popular ones hence are used in the project.\\

For multi-occupier case ... is used which looks like
but not all activities are assigned to people

The datasets are structured as a list of sensor readings---one entry per line in format: \texttt{Date}---\texttt{Time}---\texttt{SensorID}---\texttt{Value}. The fragment of such dataset is presented in \emph{Listing~\ref{lst:data}}.

% \vspace{1em}
\begin{figure}
\lstset{
  captionpos=b,
  frame=single,
  language=HTML,
  breaklines=true,
  caption=CASAS dataset structure.,
  label=lst:data,
  float=tb
}
\begin{lstlisting}
...
2008-02-26 10:52:58.577436 M17   OFF
2008-02-26 10:52:59.648222 M18   OFF       cook begin
2008-02-26 10:52:59.792264 M17   ON
...
2008-02-26 10:53:43.512642 I02   ABSENT
2008-02-26 10:53:43.978491 I01   ABSENT
...
2008-02-26 10:53:52.112690 AD1-B 0.0421491
2008-02-26 10:53:54.721822 M17   ON        phone_call end
2008-02-26 10:53:55.107910 AD1-B 0.155979
...
\end{lstlisting}
\end{figure}
% \vspace{1em}

The datasets were generated with sensors fitted into living space of house and agents performing predefined activities. The following sensors were used:
\begin{description}
\item[M\_\_] motion sensors.
\item[I\_\_] item sensors e.g.\ oatmeal, raisin, brown sugar, bowl, measuring spoon, medicine container, phone book.
\item[D01] cabinet sensor.
\item[AD1-A, AD1-B] water sensor.
\item[AD1-C] burner sensor.
\item[asterisk] phone usage.
\end{description}

The sensor layout of the apartment is shown in the \emph{Figure~\ref{fig:house}}.

\begin{figure}[htb]
  \centering%[width=.45\textwidth]
  \begin{subfigure}[b]{0.6\textwidth}
    \includegraphics[height=6.3cm]{gfx/Chinook_3_Bedroom_TH}
    \caption{\label{fig:house:a}}
  \end{subfigure}%
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[height=6.3cm]{gfx/Chinook_Cabinet}
    \caption{\label{fig:house:b}}
  \end{subfigure}%
  \caption[The sensor layout of the apartment.]{The sensor layout of the apartment~\citep{cook2009assessing}.\label{fig:house}}
\end{figure}

Participants performed five \emph{Activity of Daily Living}(ADL) tasks:
\begin{description}
\item[Make a phone call] Move to the phone in the dining room; find a specific number in the phone book; dial the number; listens to the message; summarise cooking directions provided over the phone on a notepad.
\item[Wash hands] Move into the kitchen; wash hands in the sink with hand soap; dry hands with a paper towel.
\item[Cook] Cook a pot of oatmeal according to the directions given in the phone message: measure water, pour the water into a pot; boil the water; add oats; put the oatmeal into a bowl; add raisins and brown sugar.
\item[Eat] Take cooked oatmeal; take medicine container; move to the dining room; eat the food.
\item[Clean] Take all of the dishes to the sink in the kitchen; clean them with water and dish soap.
\end{description}

    \subsection{CASAS dataset}
about casas
    \subsection{Dataset issues}
--Problems with the data -> hard to learn activity models

  \section{The smart-house generator}
--Design activities and learn them

\begin{figure}
  \centering
  \includegraphics[width=.9\textwidth]{./gfx/room_layout}
  \caption{Room layout of simulated house.}
\end{figure}

use coded background knowledge to generate data: sample path and sensor firing\\
tool to generate such data would be of great importance in testing and model building\\

data generator generates smart house data based on 4 description files:
% \section{\texttt{rooms.l}}
Defines interconnection of rooms in form of an adjacency matrix:\\
% \lstinputlisting[language=Python]{../stdg/rooms.l}

The first element in first line must be \texttt{[X]}\\
The headers must be \emph{roomName} --- must be without spaces.

% \section{\texttt{activities.l}}
This file specifies the parameters of Gaussian distribution describing \emph{activities names} in form of:\\
\texttt{nameOfActivity mean standardDeviation}

it is used to simulate time needed to accomplish activity in \emph{seconds}.

% \lstinputlisting[language=Python]{../stdg/activities.l}

% \section{\texttt{path.l}}
This files describe activities to generate in form \texttt{keyword(goal)}:\\
% \lstinputlisting[language=Python]{../stdg/path.l}

the \texttt{keywords} in this file are:\\
\begin{description}
\item[\texttt{start}] where the person starts
\item[\texttt{go}] where to go
\item[\texttt{do}] what activity to do
\end{description}

The \texttt{goals} are:
\begin{description}
\item[room names] defined in \texttt{rooms.l} file and matched with \texttt{go} or \texttt{start} keywords

\item[activities] have to be defined in both \texttt{activities.l} and \texttt{layout.l} files; are matched with \texttt{do} keywords
\end{description}


this file must start with command \texttt{start}\\
to \texttt{do} given activity you first must go to the room that it is available in.

% \section{\texttt{layout.l}}
All measures are in meters\\
the room layout description is based on cartesian coordinates with origin in bottom left corner\\

This file defines sensor layouts for each of the rooms defined in \texttt{rooms.l} file:\\
% \lstinputlisting[language=Python]{../stdg/layout.l}

each room has to be described as:
\texttt{roomName} \texttt{widthOfRoom} \texttt{heightOfRoom} \texttt{:}\\
The room description line has to be finished with \texttt{:}, without spaces.\\

followed by sensors descriptions:\\
\texttt{motionSensorID} \texttt{widthOfSensorLocation} \texttt{heightOfSensorLocation} \texttt{rangeOfSensorRadius}\\
or
\texttt{itemSensorID} \texttt{widthOfSensorLocation} \texttt{heightOfSensorLocation} \texttt{activityName}\\
or\\
door description starting with \texttt{door} keyword and finished with \texttt{roomName} to which the door lead:\\
\texttt{door} \texttt{widthOfSensorLocation} \texttt{heightOfSensorLocation} \texttt{roomName}\\

comment lines start with \texttt{;}\\

    \subsection{Capabilities}
    \subsection{Advantages}
    \subsection{ILP ready}
----generates background knowledge, positives, negatives, and location activity details
    \subsection{Proof of concept}
--Proof of the generator producing real-life data

  \section{The converter}
--Convert CASAS-like data to knowledge representation
--Handles both single and multiple residents
--Generate positive and negative examples

  \section{Cross-validation}
--Performs cross-validation on learnt rules and generated data
--Reports statistics per label (activity) and overall performance

  \section{Knowledge representation of spatio-temporal data}
    \subsection{Time representation}
--Data example - 4 time representations
4 different time representations
sequence is most suitable for this application
not sparse numbers hich are easy to iterate without exhaustive serch
but additionally timestamp is great source of information
as its of a magnitude $10^{16}$ (micro-seconds $\mu$-seconds)
but you can extract time differenc of any two sensor activations -- time elapsed since given event -- and treshold it
and finally and most notably you can discretise time stamps which is a lot easier than working with numbers in ilp and AI namely:
  time of year (winter, summer autumn, spring), month: jan, feb, , time of day: morning, afternoon, evening, night

    \subsection{Unbounded sensor readings}
just treshold them\\
info about spatio temporal data --- why they are so important and wide spread\\

    \subsection{Background knowledge}
--Background knowledge makes learnt rules universal




%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
\chapter{Inductive Logic Programming\label{ch:ILP}}
  \section{Main concept}
  built with events, where each event is based on sensor readings

\begin{figure}
  \centering
  \includegraphics[scale=.5]{./gfx/ilp}
  \caption{ILP scheme\label{fig:ilp}}
\end{figure}

\citeauthor{plotkin1972automatic} in early 1970s and \citeauthor{shapiro1983algorithmic} in early 1980s created foundation of \emph{Inductive Logic Programming}(ILP). Both authors introduced techniques and tools to learn \emph{first-order formulas}---parametrised rules that are the core of ILP---from set of facts. Since then, ILP techniques found number of interdisciplinary applications with new tools being created now and then for rules learning purposes.

  \section{Inductive Logic Programming}
The concept of Inductive Logic Programming is based on fusion of two well known techniques: \emph{inductive learning} and \emph{logic programming}. The first component facilitates building model from available observations and generating new knowledge form experience. The latter, introduces a powerful representation of knowledge as \emph{first-order logical rules}~\citep{muggleton1994inductive,muggleton1995inverse}.\\

First-order logic is more powerful than widely used \emph{propositional logic}, which builds sentences (i.e.\ rules) with facts only by using logical connectives. The first, extends propositional logic by using as part of the rules quantified variables (i.e.\ parameters) that belong to some domain of interest. The major limitation of first-order logic is its restriction to finite variable domains---it cannot describe rules built on infinite sets like real or natural numbers.\\ %  as opposed to

The power of ILP is inherited from first-order logical rules that it is built upon. First of all, ILP overcomes the use of ``limited representation formalism''---expressing data in form of a propositional logic. As many problems cannot be expressed propositionally, but it is possible in some form of first-order logic, previously difficult to solve problems can be easily tackled.\\
Moreover, ILP does not have difficulties in incorporating substantial background knowledge to the model in learning process. This feature is not very common among machine learning models, nevertheless, use of domain knowledge is ``essential for intelligent behaviour''~\citep{muggleton1994inductive}.\\

Constructing \emph{first-order clausal theories} i.e.\ hypotheses is based on combining background knowledge with information represented as facts: positive and negative examples. ILP aims at building theory that explains facts under consideration of background knowledge.\\
To this end, it uses \emph{induction} as a basic mode of inference---generalization of specific observations to theories, rather than deduction---transforming general theories to the more specific clauses.\\

The rules produced with ILP are human readable unlike models produced by majority of machine learning solutions, what gives it great advantage over competition. Easy to understand rules means that the logic models are arguably easy to manipulate. They can be changed by simply adding, deleting, and appending clauses or literals.\\

Such model representation is invaluable in \emph{scientific theory formation} and problems where data cannot be easily represented in attribute-vale language. ILP is widely used in structure-activity prediction for drug design~\citep{king1992drug,michael1992modelling} and protein secondary-structure prediction~\citep{muggleton1992protein}.\\
It is also popular in computer science in: programming assistants, algorithmic debugging, program testing and verification, and reverse engineering~\citep{shapiro1983algorithmic,bergadno1993inductive,bratko1993inductive}.\\

To construct Activity Recognition Model two popular ILP \texttt{Prolog} implementations are examined: \texttt{Aleph}\footnote{\url{http://www.cs.ox.ac.uk/activities/machlearn/Aleph/aleph.html}} and \texttt{Progol}\footnote{\url{http://www.doc.ic.ac.uk/~shm/progol.html}}.

  \section{\texttt{ALEPH}}
    \subsection{The basic algorithm}
(page 4):
\begin{enumerate}
  \item Select example.
  \item Build most-specific-clause.
  \item Search.
  \item Remove redundant.
\end{enumerate}

    \subsection{Input files}
\begin{enumerate}
  \item Background
  \item Positives
  \item Negatives
\end{enumerate}


  \section{Applications to spatio-temporal data}
pros and cons Use of background knowledge

  \section{Background knowledge}
not possible to give experiment design and structure in data\\
possible to recover partialy but hard to do, time consuming\\

in prolog and ILP it an be represent and used as knowledge:\\
structure of rooms\\
ensor layout\\

  \section{Closed Concept \& Least General Generalisation}
activity description
keep not needed clauses in body.

``A closed concept is a concept where all the necessary and sufficient conditions required to include something within the concept can be listed. For example, the concept of a triangle is closed because a three-sided polygon, and only a three-sided polygon, is a triangle. All the conditions required to call something a triangle can be, and are, listed.''

  \section{Feature discovery and feature extraction}
Rules used in a body of activity rules can be understood as features.
Therefore they can be as well extracted and used with other models

Name the most popular that I use


%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
\chapter{Sequential multi-class model---single resident\label{ch:smcm}}
presented above example both \texttt{location} and \texttt{device} rules can be transformed to become features. Rebuilt dataset may become more ``informative'' than the original one, therefore, it can improve classification carried out with variety of different machine learning models.

  \section{Evaluation measures}
  \section{Simple synthetic dataset}

Example of ILP rules learnt with \texttt{Prolog} are shown in \emph{Listing~\ref{lst:eg}}.

  \section{Synthetic CASAS \#2}
narrated datasets
  \section{CASAS \#2}
narrated datasets
  \section{Discontinuity}
Continuity rule --- introducing bias\\
Meta-rule -- smoothing out predictions
  \section{Model generality}
Generality of learnt rules (synthetic <--> genuine) Results overview
  \section{Overlapping activities}
single resident multi-label case


\vspace{1em}
\begin{figure}[htb]
\lstset{
  captionpos=b,
  frame=single,
  language=Prolog,
  breaklines=true,
  caption=Example of target rules.,
  label=lst:eg,
  float=tb
}
\begin{lstlisting}
activity(Person, cooking) :- location(Person, TimeWindow, kitchen), device(TimeWindow, hob).
activity(Person, watchingTV) :- location(Person, TimeWindow, livingRoom), device(TimeWindow, tv).

location(Person, TimeWindow, kitchen) :- sensor(1, on, TimeWindow), sensor(5, on, TimeWindow).
location(Person, TimeWindow, livingRoom) :- sensor(2, on, TimeWindow), sensor(7, on, TimeWindow).

device(TimeWindow, hob) :- sensor(101, on, TimeWindow).
device(TimeWindow, tv) :- sensor(105, on, TimeWindow).
\end{lstlisting}
\end{figure}





%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
\chapter{Multi-label model---multiple residents\label{ch:mlm}}
  \section{Evaluation measures}
  \section{Bathroom excursion}
    \subsection{Movement case}
    \subsection{Still case}

  \section{CASAS \#9}


%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
%===============================================================================
\chapter{Summary\label{ch:summary}}
generally about what i've done

  \section{Smart-house data generator}
Data generator as a helpful tool for building and testing models\\

  \section{Rule based Activity Recognition Model}
ILP can be used as one of models for activity recognition: its strong points not available (or hard to achieve) in other models

  \section{Work evaluation}
what my results mean to general public

  \section{Further development: Data Narrative\label{sec:narrative}}

Proposed here ILP tool could extend suit of available analytic technologies for activity recognition and become great foundation for \emph{Narrative Analtics} presented in \emph{Section~\ref{sec:narrative}}.

Proposed here rules learning mechanism can be extended with ``grammar'' capable of generating \emph{Narrative Analysis} of spatio-temporal data: a \emph{succinct natural language description} of a selected time-space window of the data of interest. In healthcare and smart house scenarios, such techniques can be combined with activity recognition models to generate comprehensible descriptions of monitored activities with terminology and level of detail tuned to a particular recipient. In the context of the SPHERE project these techniques would facilitate making sense from acquired data for healthcare applications in a more transparent way than is possible with black-box approaches.

    \subsection{Visualisation techniques}
Most commonly used visualisation techniques nowadays are tables, graphs, and diagrams. Unfortunately, such charts often need expertise in a field to be correctly interpreted. Moreover, aforementioned methods often trade-off clarity for completeness of shown data hence make it difficult for a broad audience to see the big picture.\\

\emph{Narrative Analysis} aims at exploring possibility of describing data with natural language. This form of expressing information contained in the data has been under-appreciated and devoted little attention in recent years. Deep learning techniques have been applied to images to generate succinct scene description, nevertheless, it has not been used with raw data.\\
An example of data narration can be found in modern smart-phone weather and calendar applications where instead of detailed weather forecast or hour-by-hour calendar events, one sentence description is presented to the user. Furthermore, in recent years \emph{narrative analytics} in combination with visualisation techniques have been proven as effective method of expressing corporate financial data.\\

Successful adaptation of \emph{Narrative Analytics} to data provided by smart houses would greatly benefit healthcare applications. Being able to deliver activity description within given time-space window and with different level of detail would provide invaluable monitoring and diagnostic tool for daily care personnel and medical staff.

    \subsection{Narrative Analytics}
Presented here extension is not restricted to smart house data. \emph{Narrative Analytics} can be applied to any spatio-temporal information---e.g.\ smart-city feed---resulting in brief situation description contained in the data. Such ``label'' gives possibility to quickly understand status of the system without time-consuming raw-data or charts interpretation. Improved response time would result in appropriate actions taken instantly, whether it is better disease diagnosis, or traffic conditions displayed in timely manner on interactive information signs.\\
Moreover, as produced description would also be hierarchical it can be formed in a ``tree'' structure with more general narratives being higher in hierarchy. Creating timetable filled with activity ``labels'' would give better insight into personal habits and routines yielding improved understanding of arising issues.\\
Furthermore, proposed here descriptive mechanisms could be extended to become a query-enabled database. In such model a user could ``ask'' a question in natural language to get narrative answer instead of numerical vector.\\

Data narration can have multiple other applications. Alternatively, it can be used to produce figure caption based on data used to draw it.

% challenges
Creating a narrative of events is composed of two major components---``grammars'' needed to transform the data: \emph{data analysis}(objective of this project) and \emph{narrative generation}.\\
The first one is deriving high-level knowledge from low-level data (sensor input) with ILP. The latter is ``translating'' extracted information into natural language description, which also can be done using similar approach.


\begin{center}
\noindent \line(1,0){250}
\end{center}

\bibliography{yhpargoil}{}
\bibliographystyle{plainnat}
% \bibliographystyle{plain}

\end{document}

% useful expressions:
%% aggregate signal
